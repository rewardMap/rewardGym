@article{delgadoTrackingHemodynamicResponses2000,
  title = {Tracking the {{Hemodynamic Responses}} to {{Reward}} and {{Punishment}}  in the {{Striatum}}},
  author = {Delgado, M. R. and Nystrom, L. E. and Fissell, C. and Noll, D. C. and Fiez, J. A.},
  year = {2000},
  month = dec,
  journal = {Journal of Neurophysiology},
  volume = {84},
  number = {6},
  pages = {3072--3077},
  publisher = {{American Physiological Society}},
  issn = {0022-3077},
  doi = {10.1152/jn.2000.84.6.3072},
  urldate = {2022-09-15},
  abstract = {Research suggests that the basal ganglia complex is a major component of the neural circuitry that mediates reward-related processing. However, human studies have not yet characterized the response of the basal ganglia to an isolated reward, as has been done in animals. We developed an event-related functional magnetic resonance imaging paradigm to identify brain areas that are activated after presentation of a reward. Subjects guessed whether the value of a card was higher or lower than the number 5, with monetary rewards as an incentive for correct guesses. They received reward, punishment, or neutral feedback on different trials. Regions in the dorsal and ventral striatum were activated by the paradigm, showing differential responses to reward and punishment. Activation was sustained following a reward feedback, but decreased below baseline following a punishment feedback.},
  file = {/Users/simons/Zotero/storage/NXS7TG9X/Delgado et al. - 2000 - Tracking the Hemodynamic Responses to Reward and P.pdf}
}

@article{dawModelBasedInfluencesHumans2011,
  title = {Model-{{Based Influences}} on {{Humans}}' {{Choices}} and {{Striatal Prediction Errors}}},
  author = {Daw, Nathaniel~D. and Gershman, Samuel~J. and Seymour, Ben and Dayan, Peter and Dolan, Raymond~J.},
  year = {2011},
  month = mar,
  journal = {Neuron},
  volume = {69},
  number = {6},
  pages = {1204--1215},
  issn = {08966273},
  doi = {10.1016/j.neuron.2011.02.027},
  urldate = {2023-09-01},
  abstract = {The mesostriatal dopamine system is prominently implicated in model-free reinforcement learning, with fMRI BOLD signals in ventral striatum notably covarying with model-free prediction errors. However, latent learning and devaluation studies show that behavior also shows hallmarks of model-based planning, and the interaction between model-based and model-free values, prediction errors, and preferences is underexplored. We designed a multistep decision task in which modelbased and model-free influences on human choice behavior could be distinguished. By showing that choices reflected both influences we could then test the purity of the ventral striatal BOLD signal as a model-free report. Contrary to expectations, the signal reflected both model-free and modelbased predictions in proportions matching those that best explained choice behavior. These results challenge the notion of a separate model-free learner and suggest a more integrated computational architecture for high-level human decisionmaking.},
  langid = {english},
  file = {/Users/simons/Zotero/storage/BSWQRYY5/Daw et al. - 2011 - Model-Based Influences on Humans' Choices and Stri.pdf}
}

@article{nussenbaumMovingDevelopmentalResearch2020,
  title = {Moving {{Developmental Research Online}}: {{Comparing In-Lab}} and {{Web-Based Studies}} of {{Model-Based Reinforcement Learning}}},
  shorttitle = {Moving {{Developmental Research Online}}},
  author = {Nussenbaum, Kate and Scheuplein, Maximilian and Phaneuf, Camille V. and Evans, Michael D. and Hartley, Catherine A.},
  year = {2020},
  month = nov,
  journal = {Collabra: Psychology},
  volume = {6},
  number = {1},
  pages = {17213},
  issn = {2474-7394},
  doi = {10.1525/collabra.17213},
  urldate = {2023-09-01},
  abstract = {For years, adult psychological research has benefitted from web-based data collection. There is growing interest in harnessing this approach to facilitate data collection from children and adolescents to address foundational questions about cognitive development. To date, however, few studies have directly tested whether findings from in-lab developmental psychology tasks can be replicated online, particularly in the domain of value-based learning and decision-making. To address this question, we set up a pipeline for online data collection with children, adolescents, and adults, and conducted a replication of Decker et al.~(2016). The original in-lab study employed a sequential decision-making paradigm to examine shifts in value-learning strategies from childhood to adulthood. Here, we used the same paradigm in a sample of 151 children (N = 50; ages 8 - 12 years), adolescents (N = 50; ages 13 - 17 years), and adults (N = 51; ages 18 - 25 years) and replicated the main finding that the use of a ``model-based'' learning strategy increases with age. In addition, we adapted a new index of abstract reasoning (MaRs-IB; Chierchia et al.~2019) for use online, and replicated a key result from Potter et al.~(2017), which found that abstract reasoning ability mediated the relation between age and model-based learning. Our re-analyses of two previous in-lab datasets alongside our analysis of our online dataset revealed few qualitative differences across task administrations. These findings suggest that with appropriate precautions, researchers can effectively examine developmental differences in learning computations through unmoderated, online experiments.},
  file = {/Users/simons/Desktop/paper_collection/zotero_sync/2020/Nussenbaum_2020_Collabra_Psychology_Moving.pdf;/Users/simons/Zotero/storage/Z66BPXXL/Moving-Developmental-Research-Online-Comparing-In.html}
}

@article{caseyAdolescentBrainCognitive2018,
  title = {The {{Adolescent Brain Cognitive Development}} ({{ABCD}}) Study: {{Imaging}} Acquisition across 21 Sites},
  shorttitle = {The {{Adolescent Brain Cognitive Development}} ({{ABCD}}) Study},
  author = {Casey, B.J. and Cannonier, Tariq and Conley, May I. and Cohen, Alexandra O. and Barch, Deanna M. and Heitzeg, Mary M. and Soules, Mary E. and Teslovich, Theresa and Dellarco, Danielle V. and Garavan, Hugh and Orr, Catherine A. and Wager, Tor D. and Banich, Marie T. and Speer, Nicole K. and Sutherland, Matthew T. and Riedel, Michael C. and Dick, Anthony S. and Bjork, James M. and Thomas, Kathleen M. and Chaarani, Bader and Mejia, Margie H. and Hagler, Donald J. and Daniela Cornejo, M. and Sicat, Chelsea S. and Harms, Michael P. and Dosenbach, Nico U.F. and Rosenberg, Monica and Earl, Eric and Bartsch, Hauke and Watts, Richard and Polimeni, Jonathan R. and Kuperman, Joshua M. and Fair, Damien A. and Dale, Anders M.},
  year = {2018},
  month = aug,
  journal = {Developmental Cognitive Neuroscience},
  volume = {32},
  pages = {43--54},
  issn = {18789293},
  doi = {10.1016/j.dcn.2018.03.001},
  urldate = {2022-11-02},
  langid = {english},
  file = {/Users/simons/Desktop/paper_collection/zotero_sync/2018/Casey_2018_Developmental_Cognitive_Neuroscience_The_Adolescent.pdf}
}

@article{knutsonFMRIVisualizationBrain2000,
  title = {{{FMRI Visualization}} of {{Brain Activity}} during a {{Monetary Incentive Delay Task}}},
  author = {Knutson, Brian and Westdorp, Andrew and Kaiser, Erica and Hommer, Daniel},
  year = {2000},
  month = jul,
  journal = {NeuroImage},
  volume = {12},
  number = {1},
  pages = {20--27},
  issn = {10538119},
  doi = {10.1006/nimg.2000.0593},
  urldate = {2022-11-02},
  langid = {english},
  file = {/Users/simons/Desktop/paper_collection/zotero_sync/2000/Knutson_2000_NeuroImage_FMRI_Visualization.pdf}
}

@article{guitart-masipGoNogoLearning2012,
  title = {Go and No-Go Learning in Reward and Punishment: {{Interactions}} between Affect and Effect},
  shorttitle = {Go and No-Go Learning in Reward and Punishment},
  author = {{Guitart-Masip}, Marc and Huys, Quentin J.M. and Fuentemilla, Lluis and Dayan, Peter and Duzel, Emrah and Dolan, Raymond J.},
  year = {2012},
  month = aug,
  journal = {NeuroImage},
  volume = {62},
  number = {1},
  pages = {154--166},
  issn = {10538119},
  doi = {10.1016/j.neuroimage.2012.04.024},
  urldate = {2022-11-03},
  langid = {english},
  file = {/Users/simons/Desktop/paper_collection/zotero_sync/2012/Guitart-Masip_2012_NeuroImage_Go_and_no-go.pdf}
}

@article{nivNeuralPredictionErrors2012,
  title = {Neural {{Prediction Errors Reveal}} a {{Risk-Sensitive Reinforcement-Learning Process}} in the {{Human Brain}}},
  author = {Niv, Yael and Edlund, Jeffrey A. and Dayan, Peter and O'Doherty, John P.},
  year = {2012},
  month = jan,
  journal = {Journal of Neuroscience},
  volume = {32},
  number = {2},
  pages = {551--562},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.5498-10.2012},
  urldate = {2023-09-21},
  abstract = {Humans and animals are exquisitely, though idiosyncratically, sensitive to risk or variance in the outcomes of their actions. Economic, psychological, and neural aspects of this are well studied when information about risk is provided explicitly. However, we must normally learn about outcomes from experience, through trial and error. Traditional models of such reinforcement learning focus on learning about the mean reward value of cues and ignore higher order moments such as variance. We used fMRI to test whether the neural correlates of human reinforcement learning are sensitive to experienced risk. Our analysis focused on anatomically delineated regions of a priori interest in the nucleus accumbens, where blood oxygenation level-dependent (BOLD) signals have been suggested as correlating with quantities derived from reinforcement learning. We first provide unbiased evidence that the raw BOLD signal in these regions corresponds closely to a reward prediction error. We then derive from this signal the learned values of cues that predict rewards of equal mean but different variance and show that these values are indeed modulated by experienced risk. Moreover, a close neurometric{\textendash}psychometric coupling exists between the fluctuations of the experience-based evaluations of risky options that we measured neurally and the fluctuations in behavioral risk aversion. This suggests that risk sensitivity is integral to human learning, illuminating economic models of choice, neuroscientific models of affective learning, and the workings of the underlying neural mechanisms.},
  chapter = {Articles},
  copyright = {Copyright {\copyright} 2012 the authors 0270-6474/12/320551-12\$15.00/0},
  langid = {english},
  pmid = {22238090},
  file = {/Users/simons/Desktop/paper_collection/zotero_sync/2012/Niv_2012_Journal_of_Neuroscience_Neural_Prediction.pdf}
}

@article{dabneyDistributionalCodeValue2020,
  title = {A Distributional Code for Value in Dopamine-Based Reinforcement Learning},
  author = {Dabney, Will and {Kurth-Nelson}, Zeb and Uchida, Naoshige and Starkweather, Clara Kwon and Hassabis, Demis and Munos, R{\'e}mi and Botvinick, Matthew},
  year = {2020},
  month = jan,
  journal = {Nature},
  volume = {577},
  number = {7792},
  pages = {671--675},
  issn = {0028-0836, 1476-4687},
  doi = {10.1038/s41586-019-1924-6},
  urldate = {2021-08-10},
  abstract = {Since its introduction, the reward prediction error (RPE) theory of dopamine has explained a wealth of empirical phenomena, providing a unifying framework for understanding the representation of reward and value in the brain1{\textendash}3. According to the now canonical theory, reward predictions are represented as a single scalar quantity, which supports learning about the expectation, or mean, of stochastic outcomes. In the present work, we propose a novel account of dopamine-based reinforcement learning. Inspired by recent artificial intelligence research on distributional reinforcement learning4{\textendash}6, we hypothesized that the brain represents possible future rewards not as a single mean, but instead as a probability distribution, effectively representing multiple future outcomes simultaneously and in parallel. This idea leads immediately to a set of empirical predictions, which we tested using single-unit recordings from mouse ventral tegmental area. Our findings provide strong evidence for a neural realization of distributional reinforcement learning.},
  langid = {english},
  file = {/Users/simons/Zotero/storage/AIUWRTDS/Dabney et al. - 2020 - A distributional code for value in dopamine-based .pdf}
}

@article{posnerOrientingAttention1980,
  title = {Orienting of Attention},
  author = {Posner, M. I.},
  year = {1980},
  month = feb,
  journal = {The Quarterly Journal of Experimental Psychology},
  volume = {32},
  number = {1},
  pages = {3--25},
  issn = {0033-555X},
  doi = {10.1080/00335558008248231},
  langid = {english},
  pmid = {7367577},
  keywords = {Attention,Humans,Orientation,Saccades,Visual Perception}
}
