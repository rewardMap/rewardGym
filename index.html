

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Welcome to rewardGym’s documentation! &mdash; rewardGym 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=d45e8c67"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="rewardGym Tutorial" href="tutorials/tutorial.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            rewardGym
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Walkthrough</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/tutorial.html">rewardGym Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/psychopy.html">rewardGym + PsychoPy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deepdive/graph_structure.html">Graph structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/psychopy_stimuli.html">PsychoPy Stimuli</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/controlling_experiments.html">Controlling the experiment</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/what_is_run_task.html">What is run task?</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/writing_agents.html">Writing your own agents.</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tasks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tasks/hcp.html">Human Connectome Project Gambling Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/mid.html">Monetary Incentive Delay Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/gonogo.html">Go / No-Go</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/two_step.html">Two-Step task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/risk_sensitive.html">Risk-Sensitive Decision Making Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/posner.html">Spatial-Cueing / Posner Task</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">(limited) API reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/environments.html">rewardgym.environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/psychopy_stimuli.html">rewardgym.psychopy_render</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">rewardGym</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Welcome to rewardGym’s documentation!</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="welcome-to-rewardgym-s-documentation">
<h1>Welcome to rewardGym’s documentation!<a class="headerlink" href="#welcome-to-rewardgym-s-documentation" title="Link to this heading"></a></h1>
<a class="reference external image-reference" href="https://doi.org/10.5281/zenodo.10942784"><img alt="https://zenodo.org/badge/DOI/10.5281/zenodo.10942784.svg" src="https://zenodo.org/badge/DOI/10.5281/zenodo.10942784.svg" />
</a>
<a class="reference external image-reference" href="https://codecov.io/gh/rewardMap/rewardGym"><img alt="https://codecov.io/gh/rewardMap/rewardGym/graph/badge.svg?token=NVVNHNP38M" src="https://codecov.io/gh/rewardMap/rewardGym/graph/badge.svg?token=NVVNHNP38M" />
</a>
<img alt="https://github.com/rewardMap/rewardGym/actions/workflows/build-sphinx.yaml/badge.svg" src="https://github.com/rewardMap/rewardGym/actions/workflows/build-sphinx.yaml/badge.svg" />
<img alt="https://github.com/rewardMap/rewardGym/actions/workflows/pip-push.yaml/badge.svg" src="https://github.com/rewardMap/rewardGym/actions/workflows/pip-push.yaml/badge.svg" />
<section id="rewardgym">
<h2>rewardGym<a class="headerlink" href="#rewardgym" title="Link to this heading"></a></h2>
<p>Ambitiously called <code class="docutils literal notranslate"><span class="pre">rewardGym</span></code>, this is a part of the <code class="docutils literal notranslate"><span class="pre">rewardMap</span></code> project.</p>
<p>The project’s goal is to provide two things:</p>
<ol class="arabic simple">
<li><p>A common language for reward tasks used in research.</p></li>
<li><p>A common interface to display and collect data for these tasks.</p></li>
</ol>
<p>Under the hood this module uses the <a class="reference external" href="https://github.com/Farama-Foundation/Gymnasium">gymnasium</a> <a class="reference internal" href="#cit1" id="id1"><span>[cit1]</span></a>. The general package has
been greatly inspired by <a class="reference external" href="https://github.com/awjuliani/neuro-nav">neuro-nav</a> <a class="reference internal" href="#cit2" id="id2"><span>[cit2]</span></a>, especially the use of a graph structure to represent the tasks.</p>
<p>Many thanks also to <a class="reference external" href="https://github.com/physiopy">physiopy</a>, from where I took many of the workflows and
automatization around the repository (such as workflows and PR labels)!</p>
<img alt="docs/images/rewardGym_structure.svg" src="docs/images/rewardGym_structure.svg" />
<section id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="Link to this heading"></a></h3>
<p>I recommend creating a new python environment (using e.g. <code class="docutils literal notranslate"><span class="pre">venv</span></code> or <code class="docutils literal notranslate"><span class="pre">conda</span></code>).</p>
<p>Then install the package and all necessary dependencies using:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">rewardMap</span><span class="o">/</span><span class="n">rewardGym</span>
</pre></div>
</div>
<p>Alternatively, download / clone the repository and install from there:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">rewardMap</span><span class="o">/</span><span class="n">rewardGym</span>
<span class="n">cd</span> <span class="n">rewardGym</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">.</span>
</pre></div>
</div>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Link to this heading"></a></h3>
<p>The package should be importable as usually. See the <a class="reference external" href="https://rewardmap.github.io/rewardGym/">documentation</a> for further information.</p>
<section id="use-psychopy-for-data-collection">
<h4>Use PsychoPy for data collection<a class="headerlink" href="#use-psychopy-for-data-collection" title="Link to this heading"></a></h4>
<p>There might be cases, where you want to use this package purely for data collection.</p>
<p>The current release, basic logging is supported.</p>
<p>This is also possible using <a class="reference external" href="https://psychopy.org/">PsychoPy</a> Standalone <a class="reference internal" href="#cit3" id="id3"><span>[cit3]</span></a> (only tested version v2023.2.3, early v2024 versions were incompatible due to the GUI structure).</p>
<p>For this clone or download the repository.</p>
<p>E.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">rewardMap</span><span class="o">/</span><span class="n">rewardGym</span>
</pre></div>
</div>
<p><strong>IMPORTANT:</strong></p>
<p>Afterwards, you can use the PsychoPy coder to run <code class="docutils literal notranslate"><span class="pre">rewardgym_psychopy.py</span></code>, which is located in the root directory.</p>
<p>Outputs of this program will be saved by default in the <code class="docutils literal notranslate"><span class="pre">data</span></code> directory.</p>
</section>
<section id="run-the-environment-and-train-an-agent">
<h4>Run the environment and train an agent<a class="headerlink" href="#run-the-environment-and-train-an-agent" title="Link to this heading"></a></h4>
<p>Running a task could look like the following</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">rewardgym</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_env</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">rewardgym.agents.base_agent</span><span class="w"> </span><span class="kn">import</span> <span class="n">QAgent</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">get_env</span><span class="p">(</span><span class="s1">&#39;hcp&#39;</span><span class="p">)</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">QAgent</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
               <span class="n">action_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">state_space</span><span class="o">=</span><span class="n">env</span><span class="o">.</span><span class="n">n_states</span><span class="p">)</span>


<span class="n">n_episodes</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_episodes</span><span class="p">):</span>

    <span class="n">obs</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>

        <span class="n">action</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">get_action</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>

        <span class="n">next_obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">truncated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">agent</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">)</span>
        <span class="n">done</span> <span class="o">=</span> <span class="n">terminated</span> <span class="ow">or</span> <span class="n">truncated</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">next_obs</span>
</pre></div>
</div>
</section>
<section id="contributing">
<h4>Contributing<a class="headerlink" href="#contributing" title="Link to this heading"></a></h4>
<p>First off, thanks for taking the time to contribute! ❤️</p>
<p>All types of contributions are encouraged and valued! Unfortunately, there is
no detailed contribution guide - but it is planned!</p>
<p>If you have a question and do not find any answers in the <a class="reference external" href="https://rewardmap.github.io/rewardGym/">Documentation</a>
or the documentation is unclear, please do not hesitate to open an <a class="reference external" href="https://github.com/rewardMap/rewardGym/issues/new">Issue</a>.</p>
<p>The same goes for any kind of bug report.</p>
<p>Before you make an enhancement, please open an issue first, where we will discuss if this is in the scope of the toolbox.</p>
<p>Finally, if you want to add a new task, also open an issue, and we will help you with implementing it in the toolbox.</p>
</section>
<section id="play-a-task-currently-out-of-order">
<h4>Play a task (currently out of order)<a class="headerlink" href="#play-a-task-currently-out-of-order" title="Link to this heading"></a></h4>
<p>To play one of the tasks using a simplified pygame implementation, you can e.g.
run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rg_play</span> <span class="n">hcp</span> <span class="o">--</span><span class="n">window</span> <span class="mi">700</span> <span class="o">--</span><span class="n">n</span> <span class="mi">5</span>
</pre></div>
</div>
<p>To play the gambling task from the human connectome project, in a window of 700 x 700 pixels for 5 trials.</p>
<p>The available tasks are:</p>
<dl class="simple">
<dt>hcp</dt><dd><p>Gambling task from the human connectome project. Response buttons are: left + right.</p>
</dd>
<dt>mid</dt><dd><p>Monetary incentive delay task. Response button is: space</p>
</dd>
<dt>two-step</dt><dd><p>The classic two-step task. Response buttons are: left + right</p>
</dd>
<dt>risk-sensitive</dt><dd><p>Risk sensitive decision making task, contains both decision tasks between to outcome and singular event. Response buttons are: Left + right</p>
</dd>
<dt>posner</dt><dd><p>Posner task. Response buttons are left + right.</p>
</dd>
<dt>gonogo</dt><dd><p>Go / No-Go task, different stimuli indicate go to win, go to punish etc. Response button is: space.</p>
</dd>
</dl>
</section>
</section>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Link to this heading"></a></h3>
<div role="list" class="citation-list">
<div class="citation" id="cit1" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">cit1</a><span class="fn-bracket">]</span></span>
<p>Towers, M., Terry, J. K., Kwiatkowski, A., Balis, J. U., Cola, G. de, Deleu, T., Goulão, M., Kallinteris, A., KG, A., Krimmel, M., Perez-Vicente, R., Pierré, A., Schulhoff, S., Tai, J. J., Shen, A. T. J., &amp; Younis, O. G. (2023). Gymnasium. Zenodo. <a class="reference external" href="https://doi.org/10.5281/zenodo.8127026">https://doi.org/10.5281/zenodo.8127026</a></p>
</div>
<div class="citation" id="cit2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">cit2</a><span class="fn-bracket">]</span></span>
<p>Juliani, A., Barnett, S., Davis, B., Sereno, M., &amp; Momennejad, I. (2022). Neuro-Nav: A Library for Neurally-Plausible Reinforcement Learning (arXiv:2206.03312). arXiv. https://doi.org/10.48550/arXiv.2206.03312</p>
</div>
<div class="citation" id="cit3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">cit3</a><span class="fn-bracket">]</span></span>
<p>Peirce, J., Gray, J. R., Simpson, S., MacAskill, M., Höchenberger, R., Sogo, H., Kastman, E., &amp; Lindeløv, J. K. (2019). PsychoPy2: Experiments in behavior made easy. Behavior Research Methods, 51(1), 195–203. <a class="reference external" href="https://doi.org/10.3758/s13428-018-01193-y">https://doi.org/10.3758/s13428-018-01193-y</a></p>
</div>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Walkthrough</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/tutorial.html">rewardGym Tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/tutorial.html#The-environment">The environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/tutorial.html#Putting-the-environment-into-action">Putting the environment into action</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/tutorial.html#Providing-Rendering">Providing Rendering</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/psychopy.html">rewardGym + PsychoPy</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/psychopy.html#adding-stimulus-representations">Adding stimulus representations</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorials/psychopy.html#full-example">Full example</a></li>
</ul>
</li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="deepdive/graph_structure.html">Graph structure</a><ul>
<li class="toctree-l2"><a class="reference internal" href="deepdive/graph_structure.html#the-basic-graph">The basic graph</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepdive/graph_structure.html#adding-probabilistic-transitions">Adding probabilistic transitions</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepdive/graph_structure.html#using-the-complete-graph-structure">Using the complete graph structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepdive/graph_structure.html#utilizing-skip-connections">Utilizing skip connections</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/psychopy_stimuli.html">PsychoPy Stimuli</a><ul>
<li class="toctree-l2"><a class="reference internal" href="deepdive/psychopy_stimuli.html#the-stimulus-class">The Stimulus Class</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/controlling_experiments.html">Controlling the experiment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="deepdive/controlling_experiments.html#controlling-timing">Controlling timing</a></li>
<li class="toctree-l2"><a class="reference internal" href="deepdive/controlling_experiments.html#controlling-conditions">Controlling Conditions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/what_is_run_task.html">What is run task?</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepdive/writing_agents.html">Writing your own agents.</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Tasks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tasks/hcp.html">Human Connectome Project Gambling Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/mid.html">Monetary Incentive Delay Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/gonogo.html">Go / No-Go</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/two_step.html">Two-Step task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/risk_sensitive.html">Risk-Sensitive Decision Making Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks/posner.html">Spatial-Cueing / Posner Task</a></li>
</ul>
</div>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">(limited) API reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api/environments.html">rewardgym.environments</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/environments.html#module-rewardgym.environments.base_env">rewardgym.environments.base_env</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/environments.html#rewardgym.environments.base_env.BaseEnv"><code class="docutils literal notranslate"><span class="pre">BaseEnv</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/environments.html#module-rewardgym.environments.render_env">rewardgym.environments.render_env</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/environments.html#rewardgym.environments.render_env.RenderEnv"><code class="docutils literal notranslate"><span class="pre">RenderEnv</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api/psychopy_stimuli.html">rewardgym.psychopy_render</a><ul>
<li class="toctree-l2"><a class="reference internal" href="api/psychopy_stimuli.html#module-rewardgym.psychopy_render.logger">rewardgym.psychopy_render.logger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.logger.ExperimentLogger"><code class="docutils literal notranslate"><span class="pre">ExperimentLogger</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.logger.MinimalLogger"><code class="docutils literal notranslate"><span class="pre">MinimalLogger</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.logger.SimulationLogger"><code class="docutils literal notranslate"><span class="pre">SimulationLogger</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/psychopy_stimuli.html#module-rewardgym.psychopy_render.psychopy_display">rewardgym.psychopy_render.psychopy_display</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.psychopy_display.ActionStimulus"><code class="docutils literal notranslate"><span class="pre">ActionStimulus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.psychopy_display.BaseStimulus"><code class="docutils literal notranslate"><span class="pre">BaseStimulus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.psychopy_display.FeedBackStimulus"><code class="docutils literal notranslate"><span class="pre">FeedBackStimulus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.psychopy_display.ImageStimulus"><code class="docutils literal notranslate"><span class="pre">ImageStimulus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.psychopy_display.TextStimulus"><code class="docutils literal notranslate"><span class="pre">TextStimulus</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/psychopy_stimuli.html#module-rewardgym.psychopy_render.advanced_display">rewardgym.psychopy_render.advanced_display</a><ul>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.advanced_display.ActionStimulusTooEarly"><code class="docutils literal notranslate"><span class="pre">ActionStimulusTooEarly</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.advanced_display.ConditionBasedDisplay"><code class="docutils literal notranslate"><span class="pre">ConditionBasedDisplay</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.advanced_display.StimuliWithResponse"><code class="docutils literal notranslate"><span class="pre">StimuliWithResponse</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.advanced_display.TextWithBorder"><code class="docutils literal notranslate"><span class="pre">TextWithBorder</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="api/psychopy_stimuli.html#rewardgym.psychopy_render.advanced_display.TwoStimuliWithResponseAndSelection"><code class="docutils literal notranslate"><span class="pre">TwoStimuliWithResponseAndSelection</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="api/psychopy_stimuli.html#module-rewardgym.stimuli">rewardgym.stimuli</a></li>
</ul>
</li>
</ul>
</div>
</section>
</section>
</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Link to this heading"></a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="tutorials/tutorial.html" class="btn btn-neutral float-right" title="rewardGym Tutorial" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Simon R. Steinkamp.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>